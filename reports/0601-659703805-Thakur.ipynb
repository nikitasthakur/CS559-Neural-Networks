{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import argparse\n",
    "import cv2\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Nikita\\\\output'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "rel_path = os.path.join(curr_dir, \"output\")\n",
    "rel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_shapes_to_edges(path):\n",
    "    data = []\n",
    "    for elem in os.listdir(path):\n",
    "        path_orig = os.path.join(path,elem)\n",
    "        \n",
    "        img = cv2.imread(path_orig, cv2.IMREAD_COLOR)\n",
    "        edges = cv2.Canny(img, 100, 200)\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "        data.append((elem.split(\"_\")[0].lower(),edges))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4b003c536141>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_shapes_to_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-364568bc370e>\u001b[0m in \u001b[0;36mraw_shapes_to_edges\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mpath_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = raw_shapes_to_edges(rel_path)\n",
    "with open(\"data.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDataset:\n",
    "\n",
    "    def __init__(self, transform):\n",
    "        with open(\"data.pickle\", \"rb\") as handle:\n",
    "            self.examples = pickle.load(handle)\n",
    "            \n",
    "        self.transform = transform\n",
    "        self.classes = {'pentagon': 0,\n",
    "                        'circle': 1,\n",
    "                        'nonagon': 2,\n",
    "                        'triangle': 3,\n",
    "                        'octagon': 4,\n",
    "                        'square': 5,\n",
    "                        'heptagon': 6,\n",
    "                        'hexagon': 7,\n",
    "                        'star': 8}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = Image.fromarray(self.examples[idx][1], 'L')\n",
    "        tensor_image = self.transform(image)\n",
    "        torch.set_printoptions(profile=\"full\")\n",
    "        sample = {\"label\": self.classes[self.examples[idx][0]], \"picture\": tensor_image}\n",
    "        return sample\n",
    "\n",
    "    def train_test_dataset(self, test_split=0.2):\n",
    "        train_size = 1-test_split\n",
    "        subsets = torch.utils.data.random_split(self, [int(len(self)*train_size),int(len(self)*test_split)])\n",
    "        datasets = {'train': subsets[0],\n",
    "                    'test': subsets[1]}\n",
    "        return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestValidate:\n",
    "\n",
    "    def __init__(self, device, batch_size, criterion, net):\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.criterion = criterion\n",
    "        self.net = net\n",
    "\n",
    "    def eval(self, dataloader):\n",
    "        def score_to_modality(scores: torch.Tensor):\n",
    "            tensor_list = scores.tolist()\n",
    "            modality = []\n",
    "            for row in tensor_list:\n",
    "                modality.append(row.index(max(row)))\n",
    "            return modality\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_correct = 0\n",
    "            t_total = 0\n",
    "            total_per_mode = [0] * 9\n",
    "            correct_per_mode = [0] * 9\n",
    "            val_losses = []\n",
    "\n",
    "            all_labels = []\n",
    "            all_predicted = []\n",
    "\n",
    "            for i, data in enumerate(dataloader):\n",
    "                inputs, labels = data[\"picture\"], data[\"label\"]\n",
    "                inputs = inputs.to(self.device)\n",
    "\n",
    "                outputs = self.net(inputs)\n",
    "                labels = labels.view(self.batch_size, -1).squeeze(1).long().to(self.device)\n",
    "                loss = self.criterion(outputs.view(self.batch_size, -1), labels)\n",
    "                val_losses.append(loss.item())\n",
    "                predicted = score_to_modality(outputs.view(self.batch_size, -1))\n",
    "\n",
    "                all_labels.extend(labels)\n",
    "                all_predicted.extend(predicted)\n",
    "\n",
    "                for o, elem in enumerate(predicted):\n",
    "                    total_per_mode[int(labels[o])] += 1\n",
    "                    if labels[o] == predicted[o]:\n",
    "                        correct_per_mode[predicted[o]] += 1\n",
    "                        t_correct += 1\n",
    "                    t_total += 1\n",
    "\n",
    "            mode_statistics = []\n",
    "            for k in range(len(correct_per_mode)):\n",
    "                if correct_per_mode[k] == 0 or total_per_mode[k] == 0:\n",
    "                    mode_statistics.append(0)\n",
    "                    continue\n",
    "                mode_statistics.append(1 / (total_per_mode[k] / correct_per_mode[k]))\n",
    "            all_labels = [int(x) for x in all_labels]\n",
    "            precision, recall, fbeta, _ = precision_recall_fscore_support(all_labels,all_predicted,average='macro')\n",
    "\n",
    "            print('Accuracy: %d %%' % (100 * t_correct / t_total))\n",
    "            print(\"Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            print(\"Mode-correct:\")\n",
    "            print(total_per_mode)\n",
    "            print(mode_statistics)\n",
    "            print(\"Precision: {:.3f}, Recall: {:.3f}, F-beta: {:.3f}\".format(precision,recall,fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShapesCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShapesCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv31 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 196, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(7056, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# class ShapesCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ShapesCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout(0.25)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(64, 128)\n",
    "#         self.fc2 = nn.Linear(128, 9)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000, 18000, Train, Test Samples\n",
      "[0,     0] loss: 0.220\n",
      "[0,    10] loss: 2.210\n",
      "[0,    20] loss: 2.187\n",
      "[0,    30] loss: 2.091\n",
      "[0,    40] loss: 1.952\n",
      "[0,    50] loss: 1.927\n",
      "[0,    60] loss: 1.907\n",
      "[0,    70] loss: 1.774\n",
      "[0,    80] loss: 1.648\n",
      "[0,    90] loss: 1.819\n",
      "[0,   100] loss: 1.694\n",
      "[0,   110] loss: 1.484\n",
      "[0,   120] loss: 1.398\n",
      "[0,   130] loss: 1.248\n",
      "[0,   140] loss: 1.160\n",
      "[0,   150] loss: 1.196\n",
      "[0,   160] loss: 1.073\n",
      "[0,   170] loss: 0.877\n",
      "[0,   180] loss: 0.831\n",
      "[0,   190] loss: 0.725\n",
      "[0,   200] loss: 0.808\n",
      "[0,   210] loss: 0.675\n",
      "[0,   220] loss: 0.583\n",
      "[0,   230] loss: 0.536\n",
      "[0,   240] loss: 0.623\n",
      "[0,   250] loss: 0.642\n",
      "[0,   260] loss: 0.511\n",
      "[0,   270] loss: 0.442\n",
      "[0,   280] loss: 0.529\n",
      "[1,     0] loss: 0.059\n",
      "[1,    10] loss: 0.454\n",
      "[1,    20] loss: 0.389\n",
      "[1,    30] loss: 0.335\n",
      "[1,    40] loss: 0.333\n",
      "[1,    50] loss: 0.305\n",
      "[1,    60] loss: 0.324\n",
      "[1,    70] loss: 0.324\n",
      "[1,    80] loss: 0.307\n",
      "[1,    90] loss: 0.280\n",
      "[1,   100] loss: 0.336\n",
      "[1,   110] loss: 0.355\n",
      "[1,   120] loss: 0.311\n",
      "[1,   130] loss: 0.285\n",
      "[1,   140] loss: 0.314\n",
      "[1,   150] loss: 0.333\n",
      "[1,   160] loss: 0.280\n",
      "[1,   170] loss: 0.232\n",
      "[1,   180] loss: 0.223\n",
      "[1,   190] loss: 0.202\n",
      "[1,   200] loss: 0.220\n",
      "[1,   210] loss: 0.241\n",
      "[1,   220] loss: 0.266\n",
      "[1,   230] loss: 0.257\n",
      "[1,   240] loss: 0.214\n",
      "[1,   250] loss: 0.184\n",
      "[1,   260] loss: 0.202\n",
      "[1,   270] loss: 0.210\n",
      "[1,   280] loss: 0.178\n",
      "[2,     0] loss: 0.017\n",
      "[2,    10] loss: 0.201\n",
      "[2,    20] loss: 0.172\n",
      "[2,    30] loss: 0.189\n",
      "[2,    40] loss: 0.173\n",
      "[2,    50] loss: 0.188\n",
      "[2,    60] loss: 0.179\n",
      "[2,    70] loss: 0.164\n",
      "[2,    80] loss: 0.145\n",
      "[2,    90] loss: 0.151\n",
      "[2,   100] loss: 0.140\n",
      "[2,   110] loss: 0.148\n",
      "[2,   120] loss: 0.151\n",
      "[2,   130] loss: 0.164\n",
      "[2,   140] loss: 0.196\n",
      "[2,   150] loss: 0.263\n",
      "[2,   160] loss: 0.210\n",
      "[2,   170] loss: 0.192\n",
      "[2,   180] loss: 0.202\n",
      "[2,   190] loss: 0.194\n",
      "[2,   200] loss: 0.182\n",
      "[2,   210] loss: 0.165\n",
      "[2,   220] loss: 0.134\n",
      "[2,   230] loss: 0.152\n",
      "[2,   240] loss: 0.144\n",
      "[2,   250] loss: 0.138\n",
      "[2,   260] loss: 0.127\n",
      "[2,   270] loss: 0.133\n",
      "[2,   280] loss: 0.132\n",
      "[3,     0] loss: 0.010\n",
      "[3,    10] loss: 0.117\n",
      "[3,    20] loss: 0.113\n",
      "[3,    30] loss: 0.099\n",
      "[3,    40] loss: 0.111\n",
      "[3,    50] loss: 0.114\n",
      "[3,    60] loss: 0.122\n",
      "[3,    70] loss: 0.116\n",
      "[3,    80] loss: 0.126\n",
      "[3,    90] loss: 0.110\n",
      "[3,   100] loss: 0.114\n",
      "[3,   110] loss: 0.121\n",
      "[3,   120] loss: 0.099\n",
      "[3,   130] loss: 0.148\n",
      "[3,   140] loss: 2.452\n",
      "[3,   150] loss: 1.151\n",
      "[3,   160] loss: 0.769\n",
      "[3,   170] loss: 0.501\n",
      "[3,   180] loss: 0.374\n",
      "[3,   190] loss: 0.316\n",
      "[3,   200] loss: 0.254\n",
      "[3,   210] loss: 0.237\n",
      "[3,   220] loss: 0.243\n",
      "[3,   230] loss: 0.231\n",
      "[3,   240] loss: 0.208\n",
      "[3,   250] loss: 0.175\n",
      "[3,   260] loss: 0.191\n",
      "[3,   270] loss: 0.172\n",
      "[3,   280] loss: 0.188\n",
      "[4,     0] loss: 0.019\n",
      "[4,    10] loss: 0.186\n",
      "[4,    20] loss: 0.169\n",
      "[4,    30] loss: 0.139\n",
      "[4,    40] loss: 0.127\n",
      "[4,    50] loss: 0.140\n",
      "[4,    60] loss: 0.121\n",
      "[4,    70] loss: 0.129\n",
      "[4,    80] loss: 0.133\n",
      "[4,    90] loss: 0.143\n",
      "[4,   100] loss: 0.130\n",
      "[4,   110] loss: 0.127\n",
      "[4,   120] loss: 0.129\n",
      "[4,   130] loss: 0.127\n",
      "[4,   140] loss: 0.128\n",
      "[4,   150] loss: 0.123\n",
      "[4,   160] loss: 0.135\n",
      "[4,   170] loss: 0.117\n",
      "[4,   180] loss: 0.122\n",
      "[4,   190] loss: 0.136\n",
      "[4,   200] loss: 0.120\n",
      "[4,   210] loss: 0.117\n",
      "[4,   220] loss: 0.102\n",
      "[4,   230] loss: 0.101\n",
      "[4,   240] loss: 0.131\n",
      "[4,   250] loss: 0.114\n",
      "[4,   260] loss: 0.107\n",
      "[4,   270] loss: 0.128\n",
      "[4,   280] loss: 0.110\n",
      "[5,     0] loss: 0.009\n",
      "[5,    10] loss: 0.099\n",
      "[5,    20] loss: 0.093\n",
      "[5,    30] loss: 0.086\n",
      "[5,    40] loss: 0.113\n",
      "[5,    50] loss: 0.097\n",
      "[5,    60] loss: 0.105\n",
      "[5,    70] loss: 0.086\n",
      "[5,    80] loss: 0.103\n",
      "[5,    90] loss: 0.090\n",
      "[5,   100] loss: 0.104\n",
      "[5,   110] loss: 0.108\n",
      "[5,   120] loss: 0.110\n",
      "[5,   130] loss: 0.135\n",
      "[5,   140] loss: 0.118\n",
      "[5,   150] loss: 0.088\n",
      "[5,   160] loss: 0.095\n",
      "[5,   170] loss: 0.103\n",
      "[5,   180] loss: 0.078\n",
      "[5,   190] loss: 0.075\n",
      "[5,   200] loss: 0.082\n",
      "[5,   210] loss: 0.082\n",
      "[5,   220] loss: 0.108\n",
      "[5,   230] loss: 0.103\n",
      "[5,   240] loss: 0.109\n",
      "[5,   250] loss: 0.097\n",
      "[5,   260] loss: 0.081\n",
      "[5,   270] loss: 0.106\n",
      "[5,   280] loss: 0.097\n",
      "[6,     0] loss: 0.011\n",
      "[6,    10] loss: 0.085\n",
      "[6,    20] loss: 0.083\n",
      "[6,    30] loss: 0.082\n",
      "[6,    40] loss: 0.081\n",
      "[6,    50] loss: 0.093\n",
      "[6,    60] loss: 0.073\n",
      "[6,    70] loss: 0.081\n",
      "[6,    80] loss: 0.077\n",
      "[6,    90] loss: 0.083\n",
      "[6,   100] loss: 0.070\n",
      "[6,   110] loss: 0.071\n",
      "[6,   120] loss: 0.073\n",
      "[6,   130] loss: 0.072\n",
      "[6,   140] loss: 0.081\n",
      "[6,   150] loss: 0.091\n",
      "[6,   160] loss: 0.112\n",
      "[6,   170] loss: 0.084\n",
      "[6,   180] loss: 0.085\n",
      "[6,   190] loss: 0.087\n",
      "[6,   200] loss: 0.093\n",
      "[6,   210] loss: 0.084\n",
      "[6,   220] loss: 0.071\n",
      "[6,   230] loss: 0.074\n",
      "[6,   240] loss: 0.075\n",
      "[6,   250] loss: 0.064\n",
      "[6,   260] loss: 0.081\n",
      "[6,   270] loss: 0.081\n",
      "[6,   280] loss: 0.089\n",
      "[7,     0] loss: 0.013\n",
      "[7,    10] loss: 0.082\n",
      "[7,    20] loss: 0.083\n",
      "[7,    30] loss: 0.088\n",
      "[7,    40] loss: 0.090\n",
      "[7,    50] loss: 0.086\n",
      "[7,    60] loss: 0.077\n",
      "[7,    70] loss: 0.085\n",
      "[7,    80] loss: 0.090\n",
      "[7,    90] loss: 0.081\n",
      "[7,   100] loss: 0.071\n",
      "[7,   110] loss: 0.075\n",
      "[7,   120] loss: 0.068\n",
      "[7,   130] loss: 0.082\n",
      "[7,   140] loss: 0.074\n",
      "[7,   150] loss: 0.073\n",
      "[7,   160] loss: 0.066\n",
      "[7,   170] loss: 0.066\n",
      "[7,   180] loss: 0.071\n",
      "[7,   190] loss: 0.064\n",
      "[7,   200] loss: 0.056\n",
      "[7,   210] loss: 0.064\n",
      "[7,   220] loss: 0.063\n",
      "[7,   230] loss: 0.068\n",
      "[7,   240] loss: 0.064\n",
      "[7,   250] loss: 0.078\n",
      "[7,   260] loss: 0.069\n",
      "[7,   270] loss: 0.070\n",
      "[7,   280] loss: 0.058\n",
      "[8,     0] loss: 0.007\n",
      "[8,    10] loss: 0.073\n",
      "[8,    20] loss: 0.065\n",
      "[8,    30] loss: 0.058\n",
      "[8,    40] loss: 0.049\n",
      "[8,    50] loss: 0.076\n",
      "[8,    60] loss: 0.071\n",
      "[8,    70] loss: 0.074\n",
      "[8,    80] loss: 0.064\n",
      "[8,    90] loss: 0.063\n",
      "[8,   100] loss: 0.069\n",
      "[8,   110] loss: 0.071\n",
      "[8,   120] loss: 0.065\n",
      "[8,   130] loss: 0.070\n",
      "[8,   140] loss: 0.054\n",
      "[8,   150] loss: 0.077\n",
      "[8,   160] loss: 0.059\n",
      "[8,   170] loss: 0.086\n",
      "[8,   180] loss: 0.075\n",
      "[8,   190] loss: 0.070\n",
      "[8,   200] loss: 0.066\n",
      "[8,   210] loss: 0.065\n",
      "[8,   220] loss: 0.058\n",
      "[8,   230] loss: 0.057\n",
      "[8,   240] loss: 0.073\n",
      "[8,   250] loss: 0.067\n",
      "[8,   260] loss: 0.067\n",
      "[8,   270] loss: 0.065\n",
      "[8,   280] loss: 0.074\n",
      "[9,     0] loss: 0.007\n",
      "[9,    10] loss: 0.055\n",
      "[9,    20] loss: 0.060\n",
      "[9,    30] loss: 0.065\n",
      "[9,    40] loss: 0.060\n",
      "[9,    50] loss: 0.065\n",
      "[9,    60] loss: 0.057\n",
      "[9,    70] loss: 0.057\n",
      "[9,    80] loss: 0.074\n",
      "[9,    90] loss: 0.064\n",
      "[9,   100] loss: 0.059\n",
      "[9,   110] loss: 0.057\n",
      "[9,   120] loss: 0.055\n",
      "[9,   130] loss: 0.073\n",
      "[9,   140] loss: 0.062\n",
      "[9,   150] loss: 0.078\n",
      "[9,   160] loss: 0.054\n",
      "[9,   170] loss: 0.062\n",
      "[9,   180] loss: 0.063\n",
      "[9,   190] loss: 0.062\n",
      "[9,   200] loss: 0.075\n",
      "[9,   210] loss: 0.069\n",
      "[9,   220] loss: 0.073\n",
      "[9,   230] loss: 0.068\n",
      "[9,   240] loss: 0.055\n",
      "[9,   250] loss: 0.059\n",
      "[9,   260] loss: 0.061\n",
      "[9,   270] loss: 0.054\n",
      "[9,   280] loss: 0.049\n",
      "Accuracy: 97 %\n",
      "Loss: 0.059501\n",
      "Mode-correct:\n",
      "[1939, 1973, 1975, 2037, 2041, 2072, 1933, 1949, 2001]\n",
      "[0.9979370809695719, 0.9518499746578813, 0.9620253164556962, 0.9837997054491899, 0.9563939245467907, 0.9806949806949807, 0.9793067770305226, 0.9784504874294511, 0.9880059970014993]\n",
      "Precision: 0.976, Recall: 0.975, F-beta: 0.975\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "losses = []\n",
    "running_loss = 0\n",
    "val_counter = 0\n",
    "epochs = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(100),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0,), (1,))])\n",
    "ds = ShapeDataset(transform)\n",
    "datasets = ds.train_test_dataset(0.2)\n",
    "dataloaders = {x: DataLoader(datasets[x], batch_size, shuffle=True, num_workers=0, drop_last=True) for x in\n",
    "               ['train', 'test']}\n",
    "\n",
    "print(\"{}, {}, Train, Test Samples\".format(len(datasets['train']),\n",
    "                                                      len(datasets['test'])))\n",
    "\n",
    "net = ShapesCNN()\n",
    "net.cuda()\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "testval = TestValidate(device,batch_size,criterion,net)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloaders[\"train\"], 0):\n",
    "        val_counter += 1\n",
    "\n",
    "        inputs, labels = data[\"picture\"], data[\"label\"]\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        labels = labels.view(batch_size, -1).squeeze(1).long().to(device)\n",
    "        loss = criterion(outputs.view(batch_size, -1), labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            losses.append(running_loss / 10)\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch, i, losses[-1]))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-6a1902ee4518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-fab70edf9f6f>\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-438ca9d94c64>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "testval.eval(dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"shapes_classifier_cnn2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Grayscale(num_output_channels=1)\n",
      "    Resize(size=100, interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0,), std=(1,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=9):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    img = transform(Image.open(image_path))\n",
    "    img = img.unsqueeze_(1)\n",
    "    #img = img.float()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.forward(img)\n",
    "        probs, classes = torch.topk(input=output, k=topk)\n",
    "        top_prob = probs.exp()\n",
    "    return probs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 4, 2, 6, 1, 3, 5, 7, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor(5)  Actual : 5\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    index = 2333\n",
    "    item = datasets['test'][index]\n",
    "    image = item['picture'].unsqueeze_(0)\n",
    "    true_target = item['label']\n",
    "    prediction = net(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(\"prediction: \",predicted_class,\" Actual :\", true_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5fec28e68b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
