{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14dd94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import argparse\n",
    "import cv2\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "306f7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shape_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shape_classifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv31 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 196, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=4, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(7056, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 9)\n",
    "\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dccf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(100),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0,), (1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc40b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape_classifier(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (conv31): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool3): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(128, 196, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool4): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=7056, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=9, bias=True)\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Shape_classifier()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bd3ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "PATH = \"./model.pth\"\n",
    "\n",
    "model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f5a0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "rel_path = os.path.join(curr_dir, \"testing\")\n",
    "image_filenames = []\n",
    "def extract_edge(images_path):\n",
    "    data = []\n",
    "    for element in os.listdir(images_path):\n",
    "        image_filenames.append(element)\n",
    "        path = os.path.join(images_path,element)\n",
    "        m = np.ones((2, 2),np.uint8)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        edges = cv2.Canny(img,100,200)\n",
    "        edges = cv2.dilate(edges,m,iterations=2)\n",
    "        data.append((element.split(\"_\")[0].lower(),edges))\n",
    "    return data,image_filenames\n",
    "\n",
    "edges_data,image_filenames = extract_edge(rel_path)\n",
    "with open(\"data_test.pickle\", \"wb\") as h:\n",
    "    pickle.dump(edges_data, h, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e23bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f781625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geometryShapes:\n",
    "\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(\"data_test.pickle\", \"rb\") as h:\n",
    "            self.constituents = pickle.load(h)\n",
    "            \n",
    "        \n",
    "        self.classes = {'pentagon': 0,\n",
    "                        'circle': 1,\n",
    "                        'nonagon': 2,\n",
    "                        'triangle': 3,\n",
    "                        'octagon': 4,\n",
    "                        'square': 5,\n",
    "                        'heptagon': 6,\n",
    "                        'hexagon': 7,\n",
    "                        'star': 8}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.constituents)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        i = Image.fromarray(self.constituents[idx][1], 'L')\n",
    "        tensor_img = self.transform(i)\n",
    "        torch.set_printoptions(profile=\"full\")\n",
    "        sample = {\"label\": self.classes[self.constituents[idx][0]], \"picture\": tensor_img}\n",
    "        return sample\n",
    "\n",
    "    def split_training_testing(self):\n",
    "        subsets = torch.utils.data.random_split(self, [int(len(self))])\n",
    "        datasets = self\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28b651f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(100),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0,), (1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3168db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "ds = geometryShapes(transform)\n",
    "datasets = ds.split_training_testing()\n",
    "dataloaders = torch.utils.data.DataLoader(datasets, batch_size=1, shuffle=True)\n",
    "l = len(datasets)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef78efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0 : 'pentagon',\n",
    "            1: 'circle' ,\n",
    "            2:'nonagon',\n",
    "            3:'triangle',\n",
    "            4:'octagon',\n",
    "            5:'square',\n",
    "            6:'heptagon',\n",
    "            7:'hexagon',\n",
    "            8:'star'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "724ad0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename :  Circle_003fd9dc-2a99-11ea-8123-8363a7ec19e6.png  prediction:  circle\n",
      "Filename :  Pentagon_47b6cfa6-2a84-11ea-8123-8363a7ec19e6.png  prediction:  pentagon\n",
      "Filename :  Square_e4dad8a2-2a95-11ea-8123-8363a7ec19e6.png  prediction:  square\n",
      "Filename :  Triangle_fffd8096-2a89-11ea-8123-8363a7ec19e6.png  prediction:  triangle\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.cpu()\n",
    "    for i in range(l):\n",
    "        item = datasets[i]\n",
    "        image = item['picture'].unsqueeze_(0)\n",
    "        prediction = model(image)\n",
    "        predicted_class = np.argmax(prediction).detach().numpy()\n",
    "        print(\"Filename : \",image_filenames[i],\" prediction: \",classes[int(predicted_class)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
